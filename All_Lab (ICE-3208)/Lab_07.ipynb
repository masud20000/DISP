{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab-07: Write a program to display the following region of a speech signal.\n",
    "• Voiced region.\n",
    "• Unvoiced region.\n",
    "• Silenced region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import librosa\n",
    "\n",
    "# Read the audio file\n",
    "y, fs = librosa.load(r\"C:\\Users\\User\\OneDrive\\Desktop\\PIC\\Audio\\harvard.wav\", sr=None)\n",
    "\n",
    "# Define frame size and overlap (in samples)\n",
    "frame_size = 256\n",
    "overlap = 128\n",
    "\n",
    "# Calculate number of frames\n",
    "num_frames = (len(y) - frame_size) // (frame_size - overlap) + 1\n",
    "\n",
    "# Initialize variables\n",
    "voiced_frames = []\n",
    "unvoiced_frames = []\n",
    "silence_frames = []\n",
    "\n",
    "# Iterate through each frame\n",
    "for i in range(num_frames):\n",
    "    # Extract current frame\n",
    "    start_idx = i * (frame_size - overlap)\n",
    "    end_idx = start_idx + frame_size\n",
    "    frame = y[start_idx:end_idx]\n",
    "\n",
    "    # Calculate energy of the frame\n",
    "    energy = np.sum(np.abs(frame)**2)\n",
    "\n",
    "    # Calculate zero-crossing rate (ZCR)\n",
    "    zcr = np.sum(np.diff(np.sign(frame)) != 0)\n",
    "\n",
    "    # Thresholds for voiced, unvoiced, and silence detection\n",
    "    voiced_threshold = 0.01 * np.max(energy)  # adjust threshold based on your audio\n",
    "    unvoiced_threshold = 0.001 * np.max(energy)  # adjust threshold based on your audio\n",
    "    silence_threshold = 0.0001 * np.max(energy)  # adjust threshold based on your audio\n",
    "\n",
    "    # Identify frame type based on energy and ZCR\n",
    "    if energy > voiced_threshold and zcr > 10:  # adjust values for voiced detection\n",
    "        voiced_frames.append(i)\n",
    "    elif energy > unvoiced_threshold and zcr < 10:  # adjust values for unvoiced detection\n",
    "        unvoiced_frames.append(i)\n",
    "    else:\n",
    "        silence_frames.append(i)\n",
    "\n",
    "# Calculate time axis for plotting\n",
    "time_axis = np.arange(len(y)) / fs\n",
    "\n",
    "# Plot the original signal and the segmented parts\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Original Signal\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time_axis, y, 'k')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Original Signal')\n",
    "plt.grid(True)\n",
    "\n",
    "# Voiced, Unvoiced, and Silence Detection\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time_axis, y, 'k')\n",
    "\n",
    "# Plot voiced segments\n",
    "for i in voiced_frames:\n",
    "    start_idx = i * (frame_size - overlap)\n",
    "    end_idx = start_idx + frame_size\n",
    "    plt.plot(time_axis[start_idx:end_idx], y[start_idx:end_idx], 'g', alpha=0.5)\n",
    "\n",
    "# Plot unvoiced segments\n",
    "for i in unvoiced_frames:\n",
    "    start_idx = i * (frame_size - overlap)\n",
    "    end_idx = start_idx + frame_size\n",
    "    plt.plot(time_axis[start_idx:end_idx], y[start_idx:end_idx], 'r', alpha=0.5)\n",
    "\n",
    "# Plot silence segments\n",
    "for i in silence_frames:\n",
    "    start_idx = i * (frame_size - overlap)\n",
    "    end_idx = start_idx + frame_size\n",
    "    plt.plot(time_axis[start_idx:end_idx], y[start_idx:end_idx], 'b', alpha=0.5)\n",
    "\n",
    "# Create custom legend entries\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='g', label='Voiced Signal'),\n",
    "    Line2D([0], [0], color='r', label='Unvoiced Signal'),\n",
    "    Line2D([0], [0], color='b', label='Silence Signal')\n",
    "]\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Voiced, Unvoiced, and Silence Detection')\n",
    "plt.legend(handles=legend_elements)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
